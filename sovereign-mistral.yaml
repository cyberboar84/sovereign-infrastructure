apiVersion: apps/v1
kind: Deployment
metadata:
  name: mistral-inference-server
  labels:
    app: mistral-triton
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mistral-triton
  template:
    metadata:
      labels:
        app: mistral-triton
    spec:
      containers:
      - name: triton-mistral
        image: nvcr.io/nvidia/tritonserver:24.10-vllm-python-py3
        imagePullPolicy: IfNotPresent
        resources:
          limits:
            nvidia.com/gpu: 2
            memory: 32Gi
          requests:
            nvidia.com/gpu: 2
            cpu: 1  # <--- CHANGED FROM 4 TO 1 TO FIT ON NODE
            memory: 16Gi
        ports:
        - containerPort: 9000
          name: http
        - containerPort: 9001
          name: grpc
        - containerPort: 9002
          name: metrics

        args:
        - "tritonserver"
        - "--model-repository=/models"
        - "--disable-auto-complete-config"
        - "--log-verbose=1"
        - "--strict-model-config=false"
        - "--http-port=9000"
        - "--grpc-port=9001"
        - "--metrics-port=9002"

        env:
        - name: LD_LIBRARY_PATH
          value: "/usr/lib/x86_64-linux-gnu:/opt/tritonserver/lib:/usr/local/nvidia/lib64"
        - name: CUDA_DEVICE_ORDER
          value: "PCI_BUS_ID"
        - name: NVIDIA_VISIBLE_DEVICES
          value: "all"
        - name: VLLM_LOGGING_LEVEL
          value: "DEBUG"
        - name: PYTHONUNBUFFERED
          value: "1"

        volumeMounts:
        - name: dshm
          mountPath: /dev/shm
        - name: model-repo
          mountPath: /models
        - name: libcuda-fix
          mountPath: /usr/lib/x86_64-linux-gnu/libcuda.so.1
        - name: libnvidia-ml-fix
          mountPath: /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1

      volumes:
      - name: model-repo
        hostPath:
          path: /mnt/sovereign-storage/models
          type: Directory
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: 16Gi
      - name: libcuda-fix
        hostPath:
          path: /usr/lib/x86_64-linux-gnu/libcuda.so.570.211.01
      - name: libnvidia-ml-fix
        hostPath:
          path: /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.570.211.01

---
apiVersion: v1
kind: Service
metadata:
  name: mistral-service
spec:
  type: NodePort
  selector:
    app: mistral-triton
  ports:
  - port: 9000
    targetPort: 9000
    name: http
    nodePort: 30900
  - port: 9001
    targetPort: 9001
    name: grpc

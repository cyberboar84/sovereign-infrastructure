apiVersion: v1
kind: Namespace
metadata:
  name: sovereign-ai
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: triton
  namespace: sovereign-ai
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: triton
  template:
    metadata:
      labels:
        app: triton
    spec:
      runtimeClassName: nvidia
      containers:
      - name: triton
        image: nvcr.io/nvidia/tritonserver:24.12-vllm-python-py3
        securityContext:
          privileged: true

        command: ["/opt/tritonserver/bin/tritonserver"]
        args:
          - "--model-repository=/model_repository"
          - "--log-verbose=1"
          - "--grpc-port=8001"
          - "--http-port=8000"
          - "--metrics-port=8002"
          - "--model-control-mode=explicit"
          - "--load-model=mistral-nemo"
        env:
          - name: CUDA_DEVICE_ORDER
            value: "PCI_BUS_ORDER"
          # 1. Hardware Pinning (Verified Working)
          - name: NVIDIA_VISIBLE_DEVICES
            value: "all"
          - name: CUDA_VISIBLE_DEVICES
            value: "0,5"
          # 2. Force Disable P2P (CRITICAL)
          - name: NCCL_P2P_DISABLE
            value: "1"
          - name: NCCL_IB_DISABLE
            value: "1"
            
          # 3. New: Force vLLM to skip the corrupt cache check
          - name: VLLM_WORKER_MULTIPROC_METHOD
            value: "spawn"
        
        livenessProbe:
          httpGet:
            path: /v2/health/live
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /v2/health/ready
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 10
          failureThreshold: 3
        resources:
          limits:
            nvidia.com/gpu: 6
            memory: 32Gi
        
        ports:
        - containerPort: 8000
        - containerPort: 8001
        
        volumeMounts:
        - name: model-repo
          mountPath: /model_repository
        - name: dshm
          mountPath: /dev/shm
          
      volumes:
      - name: model-repo
        hostPath:
          path: /mnt/sovereign-storage/models_archive  # <--- POINTS TO YOUR REAL DATA
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: 32Gi
---
apiVersion: v1
kind: Service
metadata:
  name: triton-service
  namespace: sovereign-ai
spec:
  selector:
    app: triton
  ports:
  - name: http
    port: 8000
    targetPort: 8000
  - name: grpc
    port: 8001
    targetPort: 8001
